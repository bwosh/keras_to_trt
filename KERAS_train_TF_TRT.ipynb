{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from mnist import MNIST\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D, \\\n",
    "                                    Dense, Flatten, BatchNormalization, ReLU, Reshape, Lambda\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.epsilon = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open data\n",
    "mndata = MNIST('./python-mnist/data/')\n",
    "images, labels = mndata.load_training()\n",
    "\n",
    "# convert to numpy\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# transform\n",
    "images = images.reshape(-1,28,28)#.astype(float)/255\n",
    "b = np.zeros((labels.size, labels.max()+1))\n",
    "b[np.arange(labels.size),labels] = 1\n",
    "labels = b\n",
    "\n",
    "# check\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Reshape((28,28,1), input_shape=(28,28)))\n",
    "model.add(Lambda(lambda x: K.cast(x, \"float32\")/255))\n",
    "model.add(Conv2D(8,kernel_size=(2,2)))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPool2D(pool_size=(3,3)))\n",
    "model.add(Conv2D(8,kernel_size=(2,2)))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPool2D(pool_size=(3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "opt = Adam(learning_rate=0.00005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 27, 27, 8)         40        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 27, 27, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 9, 9, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 8)           264       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 634\n",
      "Trainable params: 634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = LearningRateScheduler(lambda x: 5e-5 if x<80 else 5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/100\n",
      "54000/54000 [==============================] - 9s 173us/sample - loss: 2.2655 - acc: 0.1264 - val_loss: 2.2194 - val_acc: 0.2097\n",
      "Epoch 2/100\n",
      "54000/54000 [==============================] - 9s 176us/sample - loss: 2.1299 - acc: 0.2839 - val_loss: 2.0118 - val_acc: 0.3477\n",
      "Epoch 3/100\n",
      "54000/54000 [==============================] - 10s 184us/sample - loss: 1.8376 - acc: 0.4206 - val_loss: 1.6837 - val_acc: 0.4693\n",
      "Epoch 4/100\n",
      "54000/54000 [==============================] - 10s 188us/sample - loss: 1.5641 - acc: 0.5001 - val_loss: 1.4742 - val_acc: 0.5238\n",
      "Epoch 5/100\n",
      "54000/54000 [==============================] - 9s 174us/sample - loss: 1.3954 - acc: 0.5496 - val_loss: 1.3373 - val_acc: 0.5657\n",
      "Epoch 6/100\n",
      "54000/54000 [==============================] - 9s 173us/sample - loss: 1.2783 - acc: 0.5846 - val_loss: 1.2354 - val_acc: 0.5990\n",
      "Epoch 7/100\n",
      "54000/54000 [==============================] - 10s 185us/sample - loss: 1.1906 - acc: 0.6130 - val_loss: 1.1591 - val_acc: 0.6285\n",
      "Epoch 8/100\n",
      "54000/54000 [==============================] - 11s 196us/sample - loss: 1.1228 - acc: 0.6355 - val_loss: 1.0988 - val_acc: 0.6463\n",
      "Epoch 9/100\n",
      "54000/54000 [==============================] - 10s 191us/sample - loss: 1.0694 - acc: 0.6531 - val_loss: 1.0510 - val_acc: 0.6615\n",
      "Epoch 10/100\n",
      "54000/54000 [==============================] - 11s 200us/sample - loss: 1.0269 - acc: 0.6685 - val_loss: 1.0133 - val_acc: 0.6745\n",
      "Epoch 11/100\n",
      "54000/54000 [==============================] - 11s 209us/sample - loss: 0.9922 - acc: 0.6802 - val_loss: 0.9812 - val_acc: 0.6873\n",
      "Epoch 12/100\n",
      "54000/54000 [==============================] - 12s 227us/sample - loss: 0.9634 - acc: 0.6898 - val_loss: 0.9542 - val_acc: 0.6973\n",
      "Epoch 13/100\n",
      "54000/54000 [==============================] - 9s 168us/sample - loss: 0.9393 - acc: 0.6975 - val_loss: 0.9293 - val_acc: 0.7040\n",
      "Epoch 14/100\n",
      "54000/54000 [==============================] - 10s 176us/sample - loss: 0.9178 - acc: 0.7057 - val_loss: 0.9117 - val_acc: 0.7072\n",
      "Epoch 15/100\n",
      "54000/54000 [==============================] - 12s 224us/sample - loss: 0.8988 - acc: 0.7114 - val_loss: 0.8915 - val_acc: 0.7132\n",
      "Epoch 16/100\n",
      "54000/54000 [==============================] - 10s 191us/sample - loss: 0.8818 - acc: 0.7162 - val_loss: 0.8741 - val_acc: 0.7187\n",
      "Epoch 17/100\n",
      "54000/54000 [==============================] - 13s 237us/sample - loss: 0.8655 - acc: 0.7216 - val_loss: 0.8583 - val_acc: 0.7252\n",
      "Epoch 18/100\n",
      "54000/54000 [==============================] - 11s 204us/sample - loss: 0.8516 - acc: 0.7273 - val_loss: 0.8444 - val_acc: 0.7283\n",
      "Epoch 19/100\n",
      "54000/54000 [==============================] - 12s 217us/sample - loss: 0.8374 - acc: 0.7311 - val_loss: 0.8313 - val_acc: 0.7342\n",
      "Epoch 20/100\n",
      "54000/54000 [==============================] - 12s 221us/sample - loss: 0.8241 - acc: 0.7365 - val_loss: 0.8183 - val_acc: 0.7408\n",
      "Epoch 21/100\n",
      "54000/54000 [==============================] - 15s 282us/sample - loss: 0.8126 - acc: 0.7405 - val_loss: 0.8049 - val_acc: 0.7422\n",
      "Epoch 22/100\n",
      "54000/54000 [==============================] - 12s 219us/sample - loss: 0.8003 - acc: 0.7445 - val_loss: 0.7917 - val_acc: 0.7495\n",
      "Epoch 23/100\n",
      "54000/54000 [==============================] - 12s 214us/sample - loss: 0.7887 - acc: 0.7495 - val_loss: 0.7819 - val_acc: 0.7515\n",
      "Epoch 24/100\n",
      "54000/54000 [==============================] - 12s 215us/sample - loss: 0.7780 - acc: 0.7522 - val_loss: 0.7718 - val_acc: 0.7562\n",
      "Epoch 25/100\n",
      "54000/54000 [==============================] - 10s 190us/sample - loss: 0.7671 - acc: 0.7566 - val_loss: 0.7603 - val_acc: 0.7603\n",
      "Epoch 26/100\n",
      "54000/54000 [==============================] - 12s 223us/sample - loss: 0.7565 - acc: 0.7602 - val_loss: 0.7482 - val_acc: 0.7640\n",
      "Epoch 27/100\n",
      "54000/54000 [==============================] - 13s 232us/sample - loss: 0.7471 - acc: 0.7634 - val_loss: 0.7392 - val_acc: 0.7648\n",
      "Epoch 28/100\n",
      "54000/54000 [==============================] - 12s 223us/sample - loss: 0.7362 - acc: 0.7670 - val_loss: 0.7278 - val_acc: 0.7712\n",
      "Epoch 29/100\n",
      "54000/54000 [==============================] - 10s 188us/sample - loss: 0.7269 - acc: 0.7705 - val_loss: 0.7178 - val_acc: 0.7750\n",
      "Epoch 30/100\n",
      "54000/54000 [==============================] - 13s 249us/sample - loss: 0.7172 - acc: 0.7743 - val_loss: 0.7087 - val_acc: 0.7805\n",
      "Epoch 31/100\n",
      "54000/54000 [==============================] - 12s 226us/sample - loss: 0.7071 - acc: 0.7782 - val_loss: 0.7002 - val_acc: 0.7845\n",
      "Epoch 32/100\n",
      "54000/54000 [==============================] - 11s 211us/sample - loss: 0.6986 - acc: 0.7805 - val_loss: 0.6904 - val_acc: 0.7873\n",
      "Epoch 33/100\n",
      "54000/54000 [==============================] - 11s 206us/sample - loss: 0.6903 - acc: 0.7846 - val_loss: 0.6811 - val_acc: 0.7912\n",
      "Epoch 34/100\n",
      "54000/54000 [==============================] - 12s 229us/sample - loss: 0.6821 - acc: 0.7872 - val_loss: 0.6722 - val_acc: 0.7950\n",
      "Epoch 35/100\n",
      "54000/54000 [==============================] - 10s 193us/sample - loss: 0.6725 - acc: 0.7898 - val_loss: 0.6640 - val_acc: 0.7958\n",
      "Epoch 36/100\n",
      "54000/54000 [==============================] - 11s 198us/sample - loss: 0.6647 - acc: 0.7928 - val_loss: 0.6563 - val_acc: 0.8002\n",
      "Epoch 37/100\n",
      "54000/54000 [==============================] - 10s 191us/sample - loss: 0.6551 - acc: 0.7953 - val_loss: 0.6490 - val_acc: 0.7997\n",
      "Epoch 38/100\n",
      "54000/54000 [==============================] - 10s 190us/sample - loss: 0.6480 - acc: 0.7973 - val_loss: 0.6375 - val_acc: 0.8053\n",
      "Epoch 39/100\n",
      "54000/54000 [==============================] - 11s 195us/sample - loss: 0.6405 - acc: 0.8009 - val_loss: 0.6318 - val_acc: 0.8067\n",
      "Epoch 40/100\n",
      "54000/54000 [==============================] - 10s 184us/sample - loss: 0.6321 - acc: 0.8039 - val_loss: 0.6231 - val_acc: 0.8097\n",
      "Epoch 41/100\n",
      "54000/54000 [==============================] - 9s 175us/sample - loss: 0.6247 - acc: 0.8067 - val_loss: 0.6163 - val_acc: 0.8110\n",
      "Epoch 42/100\n",
      "54000/54000 [==============================] - 11s 206us/sample - loss: 0.6168 - acc: 0.8086 - val_loss: 0.6068 - val_acc: 0.8167\n",
      "Epoch 43/100\n",
      "54000/54000 [==============================] - 13s 242us/sample - loss: 0.6091 - acc: 0.8118 - val_loss: 0.6028 - val_acc: 0.8158\n",
      "Epoch 44/100\n",
      "54000/54000 [==============================] - 11s 203us/sample - loss: 0.6024 - acc: 0.8143 - val_loss: 0.5912 - val_acc: 0.8200\n",
      "Epoch 45/100\n",
      "54000/54000 [==============================] - 12s 222us/sample - loss: 0.5947 - acc: 0.8162 - val_loss: 0.5873 - val_acc: 0.8213\n",
      "Epoch 46/100\n",
      "54000/54000 [==============================] - 11s 197us/sample - loss: 0.5866 - acc: 0.8180 - val_loss: 0.5807 - val_acc: 0.8228\n",
      "Epoch 47/100\n",
      "54000/54000 [==============================] - 12s 231us/sample - loss: 0.5802 - acc: 0.8204 - val_loss: 0.5731 - val_acc: 0.8257\n",
      "Epoch 48/100\n",
      "54000/54000 [==============================] - 9s 164us/sample - loss: 0.5736 - acc: 0.8226 - val_loss: 0.5670 - val_acc: 0.8287\n",
      "Epoch 49/100\n",
      "54000/54000 [==============================] - 8s 157us/sample - loss: 0.5673 - acc: 0.8246 - val_loss: 0.5547 - val_acc: 0.8313\n",
      "Epoch 50/100\n",
      "54000/54000 [==============================] - 9s 171us/sample - loss: 0.5615 - acc: 0.8265 - val_loss: 0.5524 - val_acc: 0.8337\n",
      "Epoch 51/100\n",
      "54000/54000 [==============================] - 10s 179us/sample - loss: 0.5541 - acc: 0.8291 - val_loss: 0.5465 - val_acc: 0.8330\n",
      "Epoch 52/100\n",
      "54000/54000 [==============================] - 9s 169us/sample - loss: 0.5477 - acc: 0.8308 - val_loss: 0.5350 - val_acc: 0.8383\n",
      "Epoch 53/100\n",
      "54000/54000 [==============================] - 10s 181us/sample - loss: 0.5421 - acc: 0.8322 - val_loss: 0.5312 - val_acc: 0.8383\n",
      "Epoch 54/100\n",
      "54000/54000 [==============================] - 10s 184us/sample - loss: 0.5371 - acc: 0.8344 - val_loss: 0.5256 - val_acc: 0.8403\n",
      "Epoch 55/100\n",
      "54000/54000 [==============================] - 9s 162us/sample - loss: 0.5307 - acc: 0.8366 - val_loss: 0.5239 - val_acc: 0.8417\n",
      "Epoch 56/100\n",
      "54000/54000 [==============================] - 11s 203us/sample - loss: 0.5250 - acc: 0.8377 - val_loss: 0.5157 - val_acc: 0.8425\n",
      "Epoch 57/100\n",
      "54000/54000 [==============================] - 11s 197us/sample - loss: 0.5215 - acc: 0.8400 - val_loss: 0.5097 - val_acc: 0.8450\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000/54000 [==============================] - 9s 162us/sample - loss: 0.5147 - acc: 0.8410 - val_loss: 0.5083 - val_acc: 0.8447\n",
      "Epoch 59/100\n",
      "54000/54000 [==============================] - 9s 159us/sample - loss: 0.5108 - acc: 0.8428 - val_loss: 0.5023 - val_acc: 0.8470\n",
      "Epoch 60/100\n",
      "54000/54000 [==============================] - 11s 213us/sample - loss: 0.5061 - acc: 0.8449 - val_loss: 0.4989 - val_acc: 0.8473\n",
      "Epoch 61/100\n",
      "54000/54000 [==============================] - 12s 213us/sample - loss: 0.5014 - acc: 0.8463 - val_loss: 0.4950 - val_acc: 0.8508\n",
      "Epoch 62/100\n",
      "54000/54000 [==============================] - 15s 286us/sample - loss: 0.4956 - acc: 0.8476 - val_loss: 0.4919 - val_acc: 0.8522\n",
      "Epoch 63/100\n",
      "54000/54000 [==============================] - 12s 215us/sample - loss: 0.4927 - acc: 0.8493 - val_loss: 0.4903 - val_acc: 0.8533\n",
      "Epoch 64/100\n",
      "54000/54000 [==============================] - 14s 260us/sample - loss: 0.4874 - acc: 0.8499 - val_loss: 0.4804 - val_acc: 0.8525\n",
      "Epoch 65/100\n",
      "54000/54000 [==============================] - 12s 221us/sample - loss: 0.4839 - acc: 0.8515 - val_loss: 0.4822 - val_acc: 0.8547\n",
      "Epoch 66/100\n",
      "54000/54000 [==============================] - 11s 198us/sample - loss: 0.4798 - acc: 0.8524 - val_loss: 0.4727 - val_acc: 0.8568\n",
      "Epoch 67/100\n",
      "54000/54000 [==============================] - 13s 236us/sample - loss: 0.4764 - acc: 0.8535 - val_loss: 0.4720 - val_acc: 0.8558\n",
      "Epoch 68/100\n",
      "54000/54000 [==============================] - 16s 289us/sample - loss: 0.4721 - acc: 0.8541 - val_loss: 0.4689 - val_acc: 0.8573\n",
      "Epoch 69/100\n",
      "54000/54000 [==============================] - 16s 295us/sample - loss: 0.4673 - acc: 0.8563 - val_loss: 0.4630 - val_acc: 0.8603\n",
      "Epoch 70/100\n",
      "54000/54000 [==============================] - 12s 220us/sample - loss: 0.4649 - acc: 0.8567 - val_loss: 0.4599 - val_acc: 0.8613\n",
      "Epoch 71/100\n",
      "54000/54000 [==============================] - 12s 225us/sample - loss: 0.4607 - acc: 0.8578 - val_loss: 0.4549 - val_acc: 0.8628\n",
      "Epoch 72/100\n",
      "54000/54000 [==============================] - 14s 265us/sample - loss: 0.4581 - acc: 0.8593 - val_loss: 0.4512 - val_acc: 0.8640\n",
      "Epoch 73/100\n",
      "54000/54000 [==============================] - 15s 270us/sample - loss: 0.4544 - acc: 0.8603 - val_loss: 0.4482 - val_acc: 0.8637\n",
      "Epoch 74/100\n",
      "54000/54000 [==============================] - 15s 283us/sample - loss: 0.4508 - acc: 0.8609 - val_loss: 0.4447 - val_acc: 0.8640\n",
      "Epoch 75/100\n",
      "54000/54000 [==============================] - 13s 246us/sample - loss: 0.4495 - acc: 0.8620 - val_loss: 0.4435 - val_acc: 0.8655\n",
      "Epoch 76/100\n",
      "54000/54000 [==============================] - 11s 210us/sample - loss: 0.4446 - acc: 0.8631 - val_loss: 0.4421 - val_acc: 0.8665\n",
      "Epoch 77/100\n",
      "54000/54000 [==============================] - 12s 216us/sample - loss: 0.4420 - acc: 0.8641 - val_loss: 0.4405 - val_acc: 0.8670\n",
      "Epoch 78/100\n",
      "54000/54000 [==============================] - 11s 203us/sample - loss: 0.4397 - acc: 0.8648 - val_loss: 0.4337 - val_acc: 0.8688\n",
      "Epoch 79/100\n",
      "54000/54000 [==============================] - 11s 208us/sample - loss: 0.4375 - acc: 0.8659 - val_loss: 0.4348 - val_acc: 0.8692\n",
      "Epoch 80/100\n",
      "54000/54000 [==============================] - 11s 208us/sample - loss: 0.4327 - acc: 0.8664 - val_loss: 0.4365 - val_acc: 0.8695\n",
      "Epoch 81/100\n",
      "54000/54000 [==============================] - 13s 239us/sample - loss: 0.4316 - acc: 0.8675 - val_loss: 0.4320 - val_acc: 0.8710\n",
      "Epoch 82/100\n",
      "54000/54000 [==============================] - 16s 294us/sample - loss: 0.4337 - acc: 0.8676 - val_loss: 0.4264 - val_acc: 0.8708\n",
      "Epoch 83/100\n",
      "54000/54000 [==============================] - 10s 180us/sample - loss: 0.4301 - acc: 0.8678 - val_loss: 0.4268 - val_acc: 0.8713\n",
      "Epoch 84/100\n",
      "54000/54000 [==============================] - 10s 192us/sample - loss: 0.4312 - acc: 0.8679 - val_loss: 0.4271 - val_acc: 0.8708\n",
      "Epoch 85/100\n",
      "54000/54000 [==============================] - 16s 294us/sample - loss: 0.4310 - acc: 0.8677 - val_loss: 0.4302 - val_acc: 0.8712\n",
      "Epoch 86/100\n",
      "54000/54000 [==============================] - 13s 243us/sample - loss: 0.4304 - acc: 0.8680 - val_loss: 0.4295 - val_acc: 0.8712\n",
      "Epoch 87/100\n",
      "54000/54000 [==============================] - 13s 232us/sample - loss: 0.4303 - acc: 0.8677 - val_loss: 0.4244 - val_acc: 0.8707\n",
      "Epoch 88/100\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.4300 - acc: 0.8679 - val_loss: 0.4275 - val_acc: 0.8707\n",
      "Epoch 89/100\n",
      "54000/54000 [==============================] - 15s 284us/sample - loss: 0.4303 - acc: 0.8682 - val_loss: 0.4280 - val_acc: 0.8707\n",
      "Epoch 90/100\n",
      "54000/54000 [==============================] - 13s 237us/sample - loss: 0.4294 - acc: 0.8681 - val_loss: 0.4299 - val_acc: 0.8710\n",
      "Epoch 91/100\n",
      "54000/54000 [==============================] - 11s 207us/sample - loss: 0.4275 - acc: 0.8681 - val_loss: 0.4252 - val_acc: 0.8713\n",
      "Epoch 92/100\n",
      "54000/54000 [==============================] - 12s 226us/sample - loss: 0.4282 - acc: 0.8683 - val_loss: 0.4236 - val_acc: 0.8705\n",
      "Epoch 93/100\n",
      "54000/54000 [==============================] - 17s 312us/sample - loss: 0.4283 - acc: 0.8684 - val_loss: 0.4226 - val_acc: 0.8707\n",
      "Epoch 94/100\n",
      "54000/54000 [==============================] - 15s 285us/sample - loss: 0.4281 - acc: 0.8684 - val_loss: 0.4259 - val_acc: 0.8712\n",
      "Epoch 95/100\n",
      "54000/54000 [==============================] - 12s 222us/sample - loss: 0.4278 - acc: 0.8685 - val_loss: 0.4279 - val_acc: 0.8712\n",
      "Epoch 96/100\n",
      "54000/54000 [==============================] - 14s 259us/sample - loss: 0.4294 - acc: 0.8686 - val_loss: 0.4265 - val_acc: 0.8718\n",
      "Epoch 97/100\n",
      "54000/54000 [==============================] - 14s 254us/sample - loss: 0.4268 - acc: 0.8686 - val_loss: 0.4281 - val_acc: 0.8717\n",
      "Epoch 98/100\n",
      "54000/54000 [==============================] - 11s 195us/sample - loss: 0.4271 - acc: 0.8686 - val_loss: 0.4262 - val_acc: 0.8710\n",
      "Epoch 99/100\n",
      "54000/54000 [==============================] - 11s 203us/sample - loss: 0.4259 - acc: 0.8689 - val_loss: 0.4263 - val_acc: 0.8715\n",
      "Epoch 100/100\n",
      "54000/54000 [==============================] - 11s 199us/sample - loss: 0.4271 - acc: 0.8688 - val_loss: 0.4229 - val_acc: 0.8712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x116649e50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=100, batch_size=32, validation_data=(X_test,y_test), callbacks=[scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7856666666666666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.argmax(preds,axis=1) == np.argmax(y_test,axis=1)\n",
    "np.sum(res)/len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to TF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['reshape_input'], ['dense/Sigmoid'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_inputs = [out.op.name for out in model.inputs]\n",
    "k_outputs = [out.op.name for out in model.outputs]\n",
    "k_inputs, k_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-0d92ab84a915>:26: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 23 variables.\n",
      "INFO:tensorflow:Converted 23 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "frozen_graph = freeze_session(K.get_session(), output_names=k_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_model/my_model.pb'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.write_graph(frozen_graph, \"tf_model\", \"my_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: To TRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "sess = tf.InteractiveSession(graph = graph)\n",
    "\n",
    "with tf.gfile.GFile(\"./tf_model/my_model.pb\", 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (0, 0, 0)\n",
      "INFO:tensorflow:Loaded TensorRT version: (0, 0, 0)\n",
      "INFO:tensorflow:Running against TensorRT version 0.0.0\n"
     ]
    }
   ],
   "source": [
    "converter = trt.TrtGraphConverter(\n",
    "            input_graph_def=graph_def,\n",
    "            nodes_blacklist=k_outputs,\n",
    "            max_workspace_size_bytes=1 << 32,\n",
    "            precision_mode='INT8',\n",
    "            minimum_segment_size=2,\n",
    "            is_dynamic_op=True,\n",
    "            maximum_cached_engines=100)\n",
    "trt_frozen_graph = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.core.framework.graph_pb2.GraphDef"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trt_frozen_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
